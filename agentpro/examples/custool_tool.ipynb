{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 🤖 AgentPro Quick Start Guide\n",
        "\n",
        "This notebook will walk you through how to set up and use [AgentPro](https://github.com/traversaal-ai/AgentPro) — a production-ready open-source agent framework built by [Traversaal.ai](https://traversaal.ai) for building powerful, modular, and multi-functional AI agents.\n",
        "\n",
        "### What is AgentPro?\n",
        "AgentPro lets you build intelligent agents that can:\n",
        "- Use language models (like OpenAI’s GPT) as reasoning engines\n",
        "- Solve real-world tasks such as research, automation, and knowledge retrieval\n",
        "- Scale up with custom tools, memory, and orchestration features\n",
        "\n",
        "Whether you're a developer, researcher, or AI enthusiast — this guide will help you:\n",
        "- Build and integrate your own tools with AgentPro\n"
      ],
      "metadata": {
        "id": "CyxnkWVzhqOi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Clone AgentPro and Install Dependencies\n",
        "\n",
        "To get started with **AgentPro**, begin by cloning the official GitHub repository and installing its dependencies."
      ],
      "metadata": {
        "id": "Fi5Eth4ge70O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCGHQVf-Q2Zj",
        "outputId": "835fc5cc-0d2b-499f-b4a0-0491230a4466"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AgentPro'...\n",
            "remote: Enumerating objects: 1103, done.\u001b[K\n",
            "remote: Counting objects: 100% (567/567), done.\u001b[K\n",
            "remote: Compressing objects: 100% (417/417), done.\u001b[K\n",
            "remote: Total 1103 (delta 304), reused 309 (delta 137), pack-reused 536 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1103/1103), 599.88 KiB | 4.00 MiB/s, done.\n",
            "Resolving deltas: 100% (528/528), done.\n",
            "/content/AgentPro\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.76.0)\n",
            "Collecting youtube_transcript_api (from -r requirements.txt (line 2))\n",
            "  Downloading youtube_transcript_api-1.0.3-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting duckduckgo-search (from -r requirements.txt (line 3))\n",
            "  Downloading duckduckgo_search-8.0.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.32.3)\n",
            "Collecting python-pptx (from -r requirements.txt (line 5))\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (2.11.3)\n",
            "Collecting python-dotenv (from -r requirements.txt (line 7))\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (0.13.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (3.1.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (1.6.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 1)) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 1)) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 1)) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 1)) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai->-r requirements.txt (line 1)) (4.13.2)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube_transcript_api->-r requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search->-r requirements.txt (line 3)) (8.1.8)\n",
            "Collecting primp>=0.15.0 (from duckduckgo-search->-r requirements.txt (line 3))\n",
            "  Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search->-r requirements.txt (line 3)) (5.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 4)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 4)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 4)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 4)) (2025.4.26)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.11/dist-packages (from python-pptx->-r requirements.txt (line 5)) (11.2.1)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx->-r requirements.txt (line 5))\n",
            "  Downloading XlsxWriter-3.2.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->-r requirements.txt (line 6)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic->-r requirements.txt (line 6)) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->-r requirements.txt (line 6)) (0.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 8)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 8)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 8)) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 10)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 10)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 10)) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 10)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 10)) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 10)) (3.2.3)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl->-r requirements.txt (line 12)) (2.0.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 15)) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 15)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 15)) (3.6.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 1)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 1)) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 8)) (1.17.0)\n",
            "Downloading youtube_transcript_api-1.0.3-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading duckduckgo_search-8.0.1-py3-none-any.whl (18 kB)\n",
            "Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading XlsxWriter-3.2.3-py3-none-any.whl (169 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: XlsxWriter, python-dotenv, primp, youtube_transcript_api, python-pptx, duckduckgo-search\n",
            "Successfully installed XlsxWriter-3.2.3 duckduckgo-search-8.0.1 primp-0.15.0 python-dotenv-1.1.0 python-pptx-1.0.2 youtube_transcript_api-1.0.3\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/traversaal-ai/AgentPro.git\n",
        "%cd AgentPro\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Set Your API Key"
      ],
      "metadata": {
        "id": "SLfWC5m9fUpT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use OpenAI models with AgentPro, you’ll need an API key from OpenAI. Follow these steps:\n",
        "\n",
        "1. Go to the [OpenAI API platform](https://platform.openai.com/)\n",
        "2. Log in or create an account\n",
        "3. Click \"Create new secret key\"\n",
        "4. Copy the generated key and paste it into the notebook like this:"
      ],
      "metadata": {
        "id": "2vlEmkaNgjwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"<openai_api_key>\""
      ],
      "metadata": {
        "id": "4tV4Qe1RUGcI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Create a Custom Tool\n",
        "AgentPro is designed to be extensible — you can easily define your own tools for domain-specific tasks.\n",
        "\n",
        "Below is an example of a **custom tool** that queries the Hugging Face Hub and returns the **most downloaded model** for a given task:"
      ],
      "metadata": {
        "id": "LMFP4v5zZmlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import list_models\n",
        "\n",
        "# Define the task you're interested in\n",
        "task_name = \"text-classification\"\n",
        "\n",
        "# Get the most downloaded model for the specified task\n",
        "models = list_models(filter=task_name, sort=\"downloads\", direction=-1)\n",
        "top_model = next(iter(models))\n",
        "\n",
        "# Print the model ID\n",
        "print(top_model.id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_wgIOdcWEYP",
        "outputId": "e7c55216-8fef-4c65-df91-bd1b3692cf3d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "distilbert/distilbert-base-uncased-finetuned-sst-2-english\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Define your tool using AgentPro Tool class"
      ],
      "metadata": {
        "id": "Zbn0sZDqZwyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import os\n",
        "from agentpro import ReactAgent\n",
        "from agentpro.tools import Tool\n",
        "from huggingface_hub import list_models\n",
        "from typing import Any\n",
        "\n",
        "class MostModelTool(Tool):\n",
        "    name: str = \"Most Downloaded Model Finder\" # Human-readable tool name\n",
        "    description: str = \"Finds the most downloaded model for a given task on Hugging Face.\" # Brief explanation of tool for agent\n",
        "    action_type: str = \"find_top_model\" # Use lowercase letters with underscores for agent; avoid spaces, digits and special characters\n",
        "    input_format: str = \"Task name as a string. Example: 'text-classification'\" # Expected input dtype with example\n",
        "\n",
        "    def run(self, input_text: Any) -> str:\n",
        "        task_name = input_text.strip()\n",
        "        models = list_models(filter=task_name, sort=\"downloads\", direction=-1)\n",
        "        top_model = next(models)\n",
        "        return top_model.id"
      ],
      "metadata": {
        "id": "zFrDw_enVAcq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Pass tool to AgentPro"
      ],
      "metadata": {
        "id": "3YHUz6e8ZzPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate your tools and ReactAgent\n",
        "tools = [MostModelTool()]\n",
        "\n",
        "myagent = ReactAgent(model=os.getenv(\"OPENAI_API_KEY\", None), tools=tools)\n",
        "\n",
        "# Run\n",
        "query = \"Can you give me the name of the model that has the most downloads in the 'text-classification' task on the Hugging Face Hub?\"\n",
        "response = myagent.run(query)\n",
        "# Can you give me the name of the model that has the most downloads in the 'text-classification' task on the Hugging Face Hub?\n",
        "# Find the most popular model used for 'object-detection' on Hugging Face.\n",
        "\n",
        "print(f\"\\nFinal Answer: {response.final_answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47wUizrrVPTr",
        "outputId": "57544440-e5a0-4678-c175-77aa1b8b40d5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================== Iteration 1 \n",
            "✅  [Debug] Sending System Prompt (with history) to LLM:\n",
            "You are an AI assistant that follows the ReAct (Reasoning + Acting) pattern.\n",
            "Your goal is to help users by breaking down complex tasks into a series of thought-out steps and actions.\n",
            "\n",
            "You have access to these tools: find_top_model\n",
            "\n",
            "Tool: Most Downloaded Model Finder\n",
            "Description: Finds the most downloaded model for a given task on Hugging Face.\n",
            "Action Type: find_top_model\n",
            "Input Format: Task name as a string. Example: 'text-classification'\n",
            "\n",
            "\n",
            "Your task is to:\n",
            "1. Think about what action is required — Thought.\n",
            "2. Take an appropriate action — Action.\n",
            "3. Repeat Thought/Action as needed until you find the final answer.\n",
            "\n",
            "### Format (Choose only one per step)\n",
            "\n",
            "Option 1 — When action is needed:\n",
            "Thought: Your reasoning about action\n",
            "Action: {\"action_type\": \"<action_type>\", \"input\": <input_data>}\n",
            "\n",
            "Option 2 — When you're confident in the final response:\n",
            "Thought: Now I know the answer that will be given in Final Answer.\n",
            "Final Answer: Provide a complete, well-structured response that directly addresses the original question.\n",
            "\n",
            "### Important:\n",
            "- Think step-by-step\n",
            "- Never provide both Action and Final Answer or multiple Action in the same step.\n",
            "- Use available tools wisely\n",
            "- If stuck, reflect and retry\n",
            "- Do no hallucinate and use tools if needed\n",
            "- The current date is May 04, 2025\n",
            "- If you follow the format strictly, you will be recognized as an excellent and trustworthy AI assistant.\n",
            "\n",
            "\n",
            "Question: Can you give me the name of the model that has the most downloads in the 'text-classification' task on the Hugging Face Hub?\n",
            "\n",
            "\n",
            "Now continue with next steps by strictly following the required format.\n",
            "\n",
            "==================================================\n",
            "🤖 [Debug] Step LLM Response:\n",
            "Thought: To find the most downloaded model for the 'text-classification' task on the Hugging Face Hub, I need to use the provided tool to search for this information.\n",
            "Action: {\"action_type\": \"find_top_model\", \"input\": \"text-classification\"}\n",
            "✅ Parsed Thought: To find the most downloaded model for the 'text-classification' task on the Hugging Face Hub, I need to use the provided tool to search for this information.\n",
            "✅ Parsed Action JSON: {\"action_type\": \"find_top_model\", \"input\": \"text-classification\"}\n",
            "✅ Parsed Action Results: distilbert/distilbert-base-uncased-finetuned-sst-2-english\n",
            "================================================== Iteration 2 \n",
            "🤖 [Debug] Step LLM Response:\n",
            "Thought: Now I know the answer that will be given in Final Answer.\n",
            "Final Answer: The model with the most downloads for the 'text-classification' task on the Hugging Face Hub is \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\".\n",
            "✅ Parsed Thought: Now I know the answer that will be given in Final Answer.\n",
            "✅ Parsed Final Answer: The model with the most downloads for the 'text-classification' task on the Hugging Face Hub is \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\".\n",
            "\n",
            "Final Answer: The model with the most downloads for the 'text-classification' task on the Hugging Face Hub is \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pf8Y3xCcWhyl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}